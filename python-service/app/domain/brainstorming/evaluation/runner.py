"""
í‰ê°€ ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Usage:
    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
    python -m backend.app.domain.brainstorming.evaluation.runner
    
    # íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë§Œ ì‹¤í–‰
    python -m backend.app.domain.brainstorming.evaluation.runner --case-id tc001
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List
import statistics

# ê²½ë¡œ ì„¤ì •
current_file = Path(__file__).resolve()
module_dir = current_file.parent
project_root = module_dir.parents[4]
sys.path.insert(0, str(project_root))

# ë¸Œë ˆì¸ìŠ¤í† ë° ëª¨ë“ˆ import
from backend.app.domain.brainstorming.session_manager import SessionManager
from backend.app.domain.brainstorming.ephemeral_rag import EphemeralRAG

# ChromaDB ë° OpenAI import
import chromadb
from chromadb.config import Settings as ChromaSettings
from openai import OpenAI
from dotenv import load_dotenv
import os

# í‰ê°€ ëª¨ë“ˆ import
from .judge import BrainstormingJudge
from .models import SingleRunResult, TestCaseResult, EvaluationSummary, TestCaseInput
from .criteria import WEIGHTS
from .test_cases import ALL_TEST_CASES, get_test_case_by_id

load_dotenv()


class EvaluationRunner:
    """í‰ê°€ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.session_manager = SessionManager()
        self.judge = BrainstormingJudge(model="gpt-5", temperature=1.0)
        
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.llm_model = os.getenv("LLM_MODEL", "gpt-4o")
        self.embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-large")
        
        # Permanent RAG ChromaDB
        brainstorming_path = module_dir.parent
        persist_directory = str(brainstorming_path / "data" / "chroma")
        
        self.chroma_client = chromadb.PersistentClient(
            path=persist_directory,
            settings=ChromaSettings(anonymized_telemetry=False)
        )
        
        try:
            self.permanent_collection = self.chroma_client.get_collection(
                name="brainstorming_techniques"
            )
            print("âœ… Permanent RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  Permanent RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.permanent_collection = None
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        self.results_dir = module_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
    
    def run_single_test(self, test_case: dict, run_number: int) -> SingleRunResult:
        """
        ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (1íšŒ)
        
        Args:
            test_case: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
            run_number: ì‹¤í–‰ ë²ˆí˜¸ (1, 2, 3)
        
        Returns:
            SingleRunResult: ì‹¤í–‰ ê²°ê³¼
        """
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ì‹¤í–‰ {run_number}/3: {test_case['name']}")
        print(f"{'='*60}")
        
        # 1. ì„¸ì…˜ ìƒì„±
        session_id = self.session_manager.create_session()
        print(f"âœ… ì„¸ì…˜ ìƒì„±: {session_id}")
        
        session = self.session_manager.get_session(session_id)
        
        try:
            # 2. Q1 ëª©ì  ì…ë ¥
            purpose = test_case["q1_purpose"]
            self.session_manager.update_session(session_id, {
                'q1_purpose': purpose
            })
            print(f"âœ… Q1 ëª©ì  ì…ë ¥ ì™„ë£Œ")
            
            # 3. Q3 ììœ ì—°ìƒ ì…ë ¥ + Ephemeral RAG ìƒì„±
            associations = test_case["q3_associations"]
            
            ephemeral_rag = EphemeralRAG(
                session_id=session_id,
                collection_name=session['chroma_collection'],
                chroma_client=self.chroma_client
            )
            
            ephemeral_rag.add_associations(associations)
            
            self.session_manager.update_session(session_id, {
                'q3_associations': associations,
                'ephemeral_rag_initialized': True
            })
            print(f"âœ… Q3 ììœ ì—°ìƒ ì…ë ¥ + Ephemeral RAG ìƒì„± ì™„ë£Œ")
            
            # 4. Ephemeral RAG í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords_data = ephemeral_rag.extract_keywords_by_similarity(
                purpose=purpose,
                top_k=5
            )
            extracted_keywords = [kw['keyword'] for kw in keywords_data]
            print(f"âœ… Ephemeral RAG í‚¤ì›Œë“œ ì¶”ì¶œ: {extracted_keywords}")
            
            # 5. Permanent RAG ê²€ìƒ‰
            rag_docs = []
            if self.permanent_collection:
                purpose_embedding = self.openai_client.embeddings.create(
                    input=purpose,
                    model=self.embedding_model
                ).data[0].embedding
                
                results = self.permanent_collection.query(
                    query_embeddings=[purpose_embedding],
                    n_results=3
                )
                
                if results and results.get('documents') and results['documents'][0]:
                    rag_docs = results['documents'][0]
                    print(f"âœ… Permanent RAG ê²€ìƒ‰ ì™„ë£Œ: {len(rag_docs)}ê°œ ë¬¸ì„œ")
            
            # 6. ì•„ì´ë””ì–´ ìƒì„± (ì‹¤ì œ API ë¡œì§ ë³µì œ)
            rag_context = "\n\n".join(rag_docs) if rag_docs else ""
            
            # ë„ë©”ì¸ íŒíŠ¸ëŠ” ìƒëµ (í‰ê°€ì— ì˜í–¥ ìµœì†Œí™”)
            
            prompt = f"""**ì—­í• **: ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ê¸°íšìì…ë‹ˆë‹¤.

**ëª©ì **: "{purpose}"

**ì‚¬ìš©ìì˜ ì—°ìƒ í‚¤ì›Œë“œ**: {', '.join(extracted_keywords)}

**ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ì°¸ê³ **:
{rag_context}

**ìš”êµ¬ì‚¬í•­**:
1. **ì§êµ° ì¶”ë¡ **: ëª©ì ì„ ë³´ê³  ì‚¬ìš©ìì˜ ì§êµ°(ìœ íŠœë²„, ì†Œìƒê³µì¸, ì§ì¥ì¸, í•™ìƒ, ê°œë°œì, íšŒì‚¬ì› ë“±)ì„ íŒŒì•…í•˜ì„¸ìš”.

2. **ì•„ì´ë””ì–´ 2-3ê°œ ìƒì„±**:
   - ê° ì•„ì´ë””ì–´ëŠ” **ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**í•˜ê³  **êµ¬ì²´ì **ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
   - ì¶”ìƒì ì¸ í‘œí˜„ ê¸ˆì§€ (ì˜ˆ: "ì „ëµ ìˆ˜ë¦½", "ì‹œìŠ¤í…œ êµ¬ì¶•" ë“±)
   - êµ¬ì²´ì ì¸ í–‰ë™ê³¼ ì˜ˆì‹œ ì¤‘ì‹¬ (ì˜ˆ: "GPS ê¸°ë°˜ ì£¼ë³€ ë§›ì§‘ ì¶”ì²œ", "ë„¤ì´ë²„ APIë¡œ ì¿ í° ë…¸ì¶œ")

3. **ì§êµ°ë³„ ë§ì¶¤**:
   - ìœ íŠœë²„ â†’ íœ´ëŒ€í° í•˜ë‚˜ë¡œ ì´¬ì˜ ê°€ëŠ¥í•œ ì˜ìƒ êµ¬ì¡°
   - ì†Œìƒê³µì¸ â†’ ë„¤ì´ë²„/ì¸ìŠ¤íƒ€ë¡œ ë‹¹ì¥ ì‹œì‘ ê°€ëŠ¥í•œ í™ë³´
   - ê°œë°œì â†’ ë¬´ë£Œ API + ê°„ë‹¨í•œ ì½”ë“œë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…
   - í•™ìƒ â†’ ë°œí‘œ ìë£Œ, êµ¬ê¸€ ë¬¸ì„œ, PPTë¡œ ë°”ë¡œ ì‘ì„±
   - íšŒì‚¬ì› â†’ íŒ€ ë¦¬ì†ŒìŠ¤ í™œìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ê³„íš

4. **ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ ê¸ˆì§€, í–‰ë™ ì¤‘ì‹¬ ì‘ì„±**

5. **í˜„ì‹¤ì„± ì œì•½ (ìœ ì—°)**:
   âŒ **ì ˆëŒ€ ê¸ˆì§€**: í—ˆìœ„ ë°ì´í„°(í†µê³„, ì‹œì¥ ê·œëª¨, ë¹„ìš©, ê·œì œ, ê²½ìŸì‚¬ ì‹¤ì  ë“±) ì–¸ê¸‰ ê¸ˆì§€. ëª¨ë¥´ë©´ "ì¡°ì‚¬ í•„ìš”"ë¼ê³  ëª…ì‹œ.
   âœ… **í˜„ì‹¤ì  ì‹¤í–‰ ê°€ëŠ¥ì„±**: ë¹ ë¥´ê²Œ ì‹¤í–‰ ê°€ëŠ¥(ë©°ì¹ ~ëª‡ ì£¼), ë‚®ì€ ì´ˆê¸° íˆ¬ì ë¶€ë‹´, ê¸°ì¡´ ë¦¬ì†ŒìŠ¤/ì—­ëŸ‰ìœ¼ë¡œ ê°€ëŠ¥(ê°œì¸/ì†Œê·œëª¨ íŒ€/íšŒì‚¬ ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ).
   âœ… **í–‰ë™ ì¤‘ì‹¬**: êµ¬ì²´ì ì¸ í–‰ë™ê³¼ ì˜ˆì‹œ ì¤‘ì‹¬, ê±°ì°½í•œ ì „ëµì´ë‚˜ ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ ê¸ˆì§€.

**ì¶œë ¥ í˜•ì‹**:
ì•„ì´ë””ì–´ 1: [ì œëª©]
- ì„¤ëª…: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•]

ì•„ì´ë””ì–´ 2: [ì œëª©]
- ì„¤ëª…: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•]

ì•„ì´ë””ì–´ 3: [ì œëª©] (ì„ íƒ)
- ì„¤ëª…: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•]
"""
            
            idea_response = self.openai_client.chat.completions.create(
                model=self.llm_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ê¸°íšìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            ideas_text = idea_response.choices[0].message.content.strip()
            print(f"âœ… ì•„ì´ë””ì–´ ìƒì„± ì™„ë£Œ")
            
            # 7. ì•„ì´ë””ì–´ íŒŒì‹± (ê°„ë‹¨í•˜ê²Œ)
            ideas = []
            current_idea = None
            
            for line in ideas_text.split('\n'):
                line = line.strip()
                if not line:
                    continue
                
                if line.startswith('ì•„ì´ë””ì–´'):
                    if current_idea:
                        ideas.append(current_idea)
                    
                    title = line.split(':', 1)[1].strip() if ':' in line else line
                    current_idea = {
                        'title': title,
                        'description': '',
                        'analysis': ''
                    }
                elif current_idea and line.startswith('-'):
                    content = line.lstrip('-').strip()
                    if content.startswith('ì„¤ëª…:'):
                        content = content[3:].strip()
                    current_idea['description'] += content + '\n'
            
            if current_idea:
                ideas.append(current_idea)
            
            # 8. SWOT ë¶„ì„ ì¶”ê°€
            for idea in ideas:
                swot_prompt = f"""**ì—­í• **: í˜„ì‹¤ì ì¸ ê¸°íšì

**ì•„ì´ë””ì–´**: {idea['title']}
{idea['description']}

**ìš”êµ¬ì‚¬í•­**:
1. ì´ ì•„ì´ë””ì–´ì— ëŒ€í•œ **SWOT ë¶„ì„** ìˆ˜í–‰
2. **í˜„ì‹¤ì  ê´€ì **ì—ì„œ ë¶„ì„ (ì‚¬ìš©ìì˜ ìƒí™©: ê°œì¸/ì†Œê·œëª¨ íŒ€/íšŒì‚¬)
3. ê° í•­ëª©ì„ **1-2ì¤„**ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
4. **í—ˆìœ„ ë°ì´í„° ì ˆëŒ€ ê¸ˆì§€** (ëª¨ë¥´ë©´ "ì¡°ì‚¬ í•„ìš”")

**ì¶œë ¥ í˜•ì‹**:
Strengths (ê°•ì ):
- [ê°•ì  1]
- [ê°•ì  2]

Weaknesses (ì•½ì ):
- [ì•½ì  1]
- [ì•½ì  2]

Opportunities (ê¸°íšŒ):
- [ê¸°íšŒ 1]
- [ê¸°íšŒ 2]

Threats (ìœ„í˜‘):
- [ìœ„í˜‘ 1]
- [ìœ„í˜‘ 2]
"""
                
                swot_response = self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í˜„ì‹¤ì ì¸ ê¸°íšìì…ë‹ˆë‹¤."},
                        {"role": "user", "content": swot_prompt}
                    ],
                    temperature=0.6,
                    max_tokens=500
                )
                
                idea['analysis'] = swot_response.choices[0].message.content.strip()
            
            print(f"âœ… SWOT ë¶„ì„ ì™„ë£Œ: {len(ideas)}ê°œ ì•„ì´ë””ì–´")
            
            # 9. ìµœì¢… í…ìŠ¤íŠ¸ í¬ë§·
            final_ideas_text = ""
            for i, idea in enumerate(ideas, 1):
                final_ideas_text += f"ğŸ“Œ ì•„ì´ë””ì–´ {i}: {idea['title']}\n\n"
                final_ideas_text += f"{idea['description']}\n"
                final_ideas_text += f"ğŸ“Š SWOT ë¶„ì„:\n\n{idea['analysis']}\n\n"
            
            # 10. Judge í‰ê°€
            print(f"ğŸ” Judge í‰ê°€ ì¤‘... (GPT-5)")
            scores = self.judge.evaluate(
                question=purpose,
                answer=final_ideas_text,
                permanent_rag_docs=rag_docs,
                ephemeral_keywords=extracted_keywords
            )
            
            weighted_total = scores.weighted_average(WEIGHTS)
            
            print(f"âœ… í‰ê°€ ì™„ë£Œ:")
            print(f"   - rag_utilization (RAG í™œìš©ë„): {scores.rag_utilization}/10")
            print(f"   - completeness (ë‹µë³€ ì™„ì„±ë„): {scores.completeness}/10")
            print(f"   - relevance (ì§ˆë¬¸-ë‹µë³€ ì—°ê´€ë„): {scores.relevance}/10")
            print(f"   - creativity (ì°½ì˜ì„±): {scores.creativity}/10")
            print(f"   - practicality (ì‹¤ìš©ì„±): {scores.practicality}/10")
            print(f"   - weighted_total (ê°€ì¤‘ í‰ê· ): {weighted_total}/10")
            
            # 11. ê²°ê³¼ ìƒì„±
            result = SingleRunResult(
                run_number=run_number,
                session_id=session_id,
                ideas_text=final_ideas_text,
                ideas_count=len(ideas),
                permanent_rag_docs=rag_docs,
                ephemeral_keywords=extracted_keywords,
                scores=scores,
                weighted_total=weighted_total
            )
            
            return result
            
        finally:
            # 12. ì„¸ì…˜ ì •ë¦¬
            self.session_manager.delete_session(session_id)
            print(f"âœ… ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
    
    def run_test_case(self, test_case: dict) -> TestCaseResult:
        """
        í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰ (3íšŒ ë°˜ë³µ)
        
        Args:
            test_case: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        
        Returns:
            TestCaseResult: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì „ì²´ ê²°ê³¼
        """
        print(f"\n{'#'*60}")
        print(f"ğŸš€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹œì‘: {test_case['name']} ({test_case['id']})")
        print(f"{'#'*60}")
        
        runs = []
        
        # 3íšŒ ì‹¤í–‰
        for i in range(1, 4):
            run_result = self.run_single_test(test_case, i)
            runs.append(run_result)
        
        # í‰ê·  ê³„ì‚°
        avg_rag = sum(r.scores.rag_utilization for r in runs) / 3
        avg_comp = sum(r.scores.completeness for r in runs) / 3
        avg_rel = sum(r.scores.relevance for r in runs) / 3
        avg_cre = sum(r.scores.creativity for r in runs) / 3
        avg_prac = sum(r.scores.practicality for r in runs) / 3
        avg_weighted = sum(r.weighted_total for r in runs) / 3
        
        average_scores = {
            "rag_utilization": round(avg_rag, 2),
            "completeness": round(avg_comp, 2),
            "relevance": round(avg_rel, 2),
            "creativity": round(avg_cre, 2),
            "practicality": round(avg_prac, 2),
        }
        
        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        weighted_scores = [r.weighted_total for r in runs]
        std_dev = round(statistics.stdev(weighted_scores) if len(weighted_scores) > 1 else 0.0, 2)
        
        result = TestCaseResult(
            test_case_id=test_case["id"],
            test_case_name=test_case["name"],
            runs=runs,
            average_scores=average_scores,
            average_weighted_total=round(avg_weighted, 2),
            std_deviation=std_dev
        )
        
        # í•œê¸€ ë ˆì´ë¸” ë§¤í•‘
        label_map = {
            "rag_utilization": "RAG í™œìš©ë„",
            "completeness": "ë‹µë³€ ì™„ì„±ë„",
            "relevance": "ì§ˆë¬¸-ë‹µë³€ ì—°ê´€ë„",
            "creativity": "ì°½ì˜ì„±",
            "practicality": "ì‹¤ìš©ì„±"
        }
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì™„ë£Œ: {test_case['name']}")
        print(f"{'='*60}")
        print(f"í‰ê·  ì ìˆ˜:")
        for key, value in average_scores.items():
            korean_label = label_map.get(key, key)
            print(f"  - {key} ({korean_label}): {value}/10")
        print(f"weighted_total (ê°€ì¤‘ í‰ê· ): {result.average_weighted_total}/10")
        print(f"std_deviation (í‘œì¤€í¸ì°¨): {std_dev} (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì„± ë†’ìŒ)")
        
        return result
    
    def save_result(self, result: TestCaseResult):
        """ê²°ê³¼ JSON ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{result.test_case_id}_result.json"
        filepath = self.results_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result.model_dump(), f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥: {filepath}")
    
    def run_all(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
        print(f"\n{'#'*60}")
        print(f"ğŸ¯ ì „ì²´ í‰ê°€ ì‹œì‘")
        print(f"{'#'*60}")
        print(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(ALL_TEST_CASES)}ê°œ")
        
        all_results = []
        
        for test_case in ALL_TEST_CASES:
            result = self.run_test_case(test_case)
            self.save_result(result)
            all_results.append(result)
        
        # ì „ì²´ ìš”ì•½
        overall_avg = sum(r.average_weighted_total for r in all_results) / len(all_results)
        
        summary = EvaluationSummary(
            test_cases=all_results,
            overall_average=round(overall_avg, 2),
            model_info={
                "worker_model": self.llm_model,
                "judge_model": self.judge.model,
                "embedding_model": self.embedding_model
            }
        )
        
        # ìš”ì•½ ì €ì¥
        summary_filename = f"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        summary_filepath = self.results_dir / summary_filename
        
        with open(summary_filepath, 'w', encoding='utf-8') as f:
            json.dump(summary.model_dump(), f, ensure_ascii=False, indent=2)
        
        print(f"\n{'#'*60}")
        print(f"âœ… ì „ì²´ í‰ê°€ ì™„ë£Œ!")
        print(f"{'#'*60}")
        print(f"overall_average (ì „ì²´ í‰ê·  ì ìˆ˜): {overall_avg}/10")
        print(f"summary_file (ìš”ì•½ íŒŒì¼): {summary_filepath}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ë¸Œë ˆì¸ìŠ¤í† ë° í‰ê°€ ìë™ ì‹¤í–‰")
    parser.add_argument(
        "--case-id",
        type=str,
        help="íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ID (ì˜ˆ: tc001). ìƒëµ ì‹œ ì „ì²´ ì‹¤í–‰"
    )
    
    args = parser.parse_args()
    
    runner = EvaluationRunner()
    
    if args.case_id:
        # íŠ¹ì • ì¼€ì´ìŠ¤ë§Œ ì‹¤í–‰
        test_case = get_test_case_by_id(args.case_id)
        result = runner.run_test_case(test_case)
        runner.save_result(result)
    else:
        # ì „ì²´ ì‹¤í–‰
        runner.run_all()


if __name__ == "__main__":
    main()

