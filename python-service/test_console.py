"""
ë¸Œë ˆì¸ìŠ¤í† ë° ëª¨ë“ˆ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (ì½˜ì†”ìš©)

Usage:
    conda activate brainstorm
    cd python-service
    python test_console.py
"""

import sys
from pathlib import Path

# í˜„ì¬ íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ app ë””ë ‰í† ë¦¬ ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from app.domain.brainstorming.session_manager import SessionManager
from app.domain.brainstorming.ephemeral_rag import EphemeralRAG
import chromadb
from chromadb.config import Settings as ChromaSettings
from openai import OpenAI
from dotenv import load_dotenv
import os

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def test_brainstorming():
    """ë¸Œë ˆì¸ìŠ¤í† ë° ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "="*60)
    print("ğŸ§  ë¸Œë ˆì¸ìŠ¤í† ë° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    # 1. ì´ˆê¸°í™”
    print("\n[1ë‹¨ê³„] ì´ˆê¸°í™”...")
    session_manager = SessionManager()
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    llm_model = os.getenv("LLM_MODEL", "gpt-4o")
    embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-large")
    
    # ChromaDB ë¡œë“œ
    chroma_path = current_dir / "app" / "domain" / "brainstorming" / "data" / "chroma"
    chroma_client = chromadb.PersistentClient(
        path=str(chroma_path),
        settings=ChromaSettings(anonymized_telemetry=False)
    )
    
    try:
        permanent_collection = chroma_client.get_collection(name="brainstorming_techniques")
        print("âœ… Permanent RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  Permanent RAG ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        permanent_collection = None
    
    # 2. ì„¸ì…˜ ìƒì„±
    print("\n[2ë‹¨ê³„] ì„¸ì…˜ ìƒì„±...")
    session_id = session_manager.create_session()
    print(f"âœ… ì„¸ì…˜ ID: {session_id}")
    
    try:
        # 3. Q1: ëª©ì  ì…ë ¥
        print("\n[3ë‹¨ê³„] Q1: ëª©ì  ì…ë ¥...")
        purpose = "í•™ìƒë“¤ì„ ìœ„í•œ AI ê¸°ë°˜ ë§ì¶¤í˜• í•™ìŠµ ì•± ì•„ì´ë””ì–´"
        session_manager.update_session(session_id, {'q1_purpose': purpose})
        print(f"âœ… ëª©ì : {purpose}")
        
        # 4. Q2: ì›Œë°ì—… ì§ˆë¬¸ ìƒì„± (ì„ íƒì‚¬í•­, ìƒëµ ê°€ëŠ¥)
        print("\n[4ë‹¨ê³„] Q2: ì›Œë°ì—… ì§ˆë¬¸ ìƒì„± (ìƒëµ)")
        
        # 5. Q3: ììœ ì—°ìƒ ì…ë ¥
        print("\n[5ë‹¨ê³„] Q3: ììœ ì—°ìƒ ì…ë ¥...")
        associations = ["í•™ìŠµ", "AI", "ë§ì¶¤í˜•", "í•™ìƒ", "ê³µë¶€", "íš¨ìœ¨", "ì¬ë¯¸"]
        
        session = session_manager.get_session(session_id)
        ephemeral_rag = EphemeralRAG(
            session_id=session_id,
            collection_name=session['chroma_collection'],
            chroma_client=chroma_client
        )
        
        ephemeral_rag.add_associations(associations)
        session_manager.update_session(session_id, {
            'q3_associations': associations,
            'ephemeral_rag_initialized': True
        })
        print(f"âœ… ììœ ì—°ìƒ: {associations}")
        
        # 6. í‚¤ì›Œë“œ ì¶”ì¶œ
        print("\n[6ë‹¨ê³„] Ephemeral RAG í‚¤ì›Œë“œ ì¶”ì¶œ...")
        keywords_data = ephemeral_rag.extract_keywords_by_similarity(
            purpose=purpose,
            top_k=5
        )
        extracted_keywords = [kw['keyword'] for kw in keywords_data]
        print(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {extracted_keywords}")
        
        # 7. Permanent RAG ê²€ìƒ‰
        print("\n[7ë‹¨ê³„] Permanent RAG ê²€ìƒ‰...")
        rag_docs = []
        if permanent_collection:
            purpose_embedding = openai_client.embeddings.create(
                input=purpose,
                model=embedding_model
            ).data[0].embedding
            
            results = permanent_collection.query(
                query_embeddings=[purpose_embedding],
                n_results=3
            )
            
            if results and results.get('documents') and results['documents'][0]:
                rag_docs = results['documents'][0]
                print(f"âœ… ê²€ìƒ‰ëœ ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²•: {len(rag_docs)}ê°œ")
                for i, doc in enumerate(rag_docs, 1):
                    print(f"   {i}. {doc[:100]}...")
        
        # 8. ì•„ì´ë””ì–´ ìƒì„±
        print("\n[8ë‹¨ê³„] ì•„ì´ë””ì–´ ìƒì„± ì¤‘... (LLM í˜¸ì¶œ)")
        
        rag_context = "\n\n".join(rag_docs) if rag_docs else ""
        
        prompt = f"""**ì—­í• **: ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ê¸°íšìì…ë‹ˆë‹¤.

**ëª©ì **: "{purpose}"

**ì‚¬ìš©ìì˜ ì—°ìƒ í‚¤ì›Œë“œ**: {', '.join(extracted_keywords)}

**ë¸Œë ˆì¸ìŠ¤í† ë° ê¸°ë²• ì°¸ê³ **:
{rag_context}

**ìš”êµ¬ì‚¬í•­**:
1. ìœ„ ëª©ì ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ë¥¼ 2-3ê°œ ìƒì„±í•˜ì„¸ìš”.
2. ê° ì•„ì´ë””ì–´ëŠ” ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
3. ê°„ë‹¨í•œ SWOT ë¶„ì„ë„ í¬í•¨í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹**:
ì•„ì´ë””ì–´ 1: [ì œëª©]
- ì„¤ëª…: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•]
- SWOT: [ê°„ë‹¨í•œ ë¶„ì„]

ì•„ì´ë””ì–´ 2: [ì œëª©]
- ì„¤ëª…: [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•]
- SWOT: [ê°„ë‹¨í•œ ë¶„ì„]
"""
        
        response = openai_client.chat.completions.create(
            model=llm_model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ê¸°íšìì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        
        ideas_text = response.choices[0].message.content.strip()
        
        print("\n" + "="*60)
        print("ğŸ‰ ìƒì„±ëœ ì•„ì´ë””ì–´:")
        print("="*60)
        print(ideas_text)
        
        print("\n" + "="*60)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*60)
        
    finally:
        # 9. ì„¸ì…˜ ì •ë¦¬
        print("\n[9ë‹¨ê³„] ì„¸ì…˜ ì •ë¦¬...")
        session_manager.delete_session(session_id)
        print("âœ… ì„¸ì…˜ ì‚­ì œ ì™„ë£Œ")


if __name__ == "__main__":
    try:
        test_brainstorming()
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
